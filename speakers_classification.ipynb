{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import python_speech_features\n",
    "from python_speech_features import mfcc\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction\n",
    "With the help of `file` command in terminal, we are easily to find that the information of flac files: \n",
    "\n",
    "FLAC `audio bitstream data, 16 bit, mono, 16 kHz, 33440 samples`\n",
    "\n",
    "The first step is to extract the MFCC features of all the sound files spoken by every speaker. You can try to set the variable `generate` as `True`, or you can skip this step and load the data by `pickle`. More details are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = False # variable used for generate clean input training data by yourself.\n",
    "\n",
    "if generate:\n",
    "    \n",
    "    base_string = './LibriSpeech/dev-clean'\n",
    "    speakers = []\n",
    "    for filename in glob.glob(base_string + '/*'):\n",
    "        new_string = base_string + '/'\n",
    "        speakers.append(filename.replace(new_string,''))\n",
    "\n",
    "    speakers_chapters = {}\n",
    "    for speaker in speakers:\n",
    "        speakers_chapters[speaker] = {}\n",
    "        for filename in glob.glob(base_string + '/' + speaker + '/*'):\n",
    "            new_string = base_string + '/' + speaker + '/'\n",
    "            chapter = filename.replace(new_string,'')\n",
    "            speakers_chapters[speaker][chapter] = []\n",
    "\n",
    "    for speaker in speakers_chapters:\n",
    "        for chapter in speakers_chapters[speaker]:\n",
    "            path = base_string + '/' + speaker + '/' + chapter + '/' + '*.flac'\n",
    "            file_list = glob.glob(path)\n",
    "            for file in file_list:\n",
    "                with open('%s'%file, 'rb') as f:\n",
    "                    data, samplerate = sf.read(f)\n",
    "                    mfcc_feat = mfcc(data,samplerate)\n",
    "                    mfcc_f = avg_mfcc = np.mean(mfcc_feat, axis = 0)\n",
    "                    speakers_chapters[speaker][chapter].append(mfcc_f)\n",
    "    '''\n",
    "    Until now, I load all the .flac sound files and their mfcc features into a dictionary. The shapes of one mfcc \n",
    "    feature is 13, which represents 13 bandwidths between low frequency to high frequency of human voice. \n",
    "    \n",
    "    Also, I notice that the lengths of the sound files vary from files to files, which will result the shapes of \n",
    "    mfcc features differently. So, I calculate the mean of all mfcc features of one speakers. \n",
    "    \n",
    "    I think this method is resonable and scientific because usually a human speaks in different frequencies toward\n",
    "    different sentences, and average operation can reduce this variance and the result can represent different  \n",
    "    people more reliable.\n",
    "    '''\n",
    "\n",
    "    raw_label = []\n",
    "    with open('./LibriSpeech/SPEAKERS.TXT', newline='') as inputfile:\n",
    "        for row in csv.reader(inputfile):\n",
    "            if '|' in row[0]:\n",
    "                raw_label.append(str(row[0]))\n",
    "    raw_label = raw_label[2:]\n",
    "\n",
    "    labels = {}\n",
    "    for i in range(0, len(raw_label)):\n",
    "        raw_label[i] = raw_label[i][0:raw_label[i].index('|')+4]\n",
    "        number, label = raw_label[i].replace(\" \", \"\").split('|')\n",
    "        if label == 'F':\n",
    "            labels[number] = 0\n",
    "        else:\n",
    "            labels[number] = 1\n",
    "    '''\n",
    "    I generate the labels of different speakers by the .txt file provided by the dataset.\n",
    "    '''\n",
    "\n",
    "    training_data = []\n",
    "    for speaker in speakers:\n",
    "        files_of_one_speaker = list(speakers_chapters[speaker].values())\n",
    "        files_of_one_speaker = sum(files_of_one_speaker, [])\n",
    "        training_data.append(files_of_one_speaker)\n",
    "\n",
    "    training_label = []\n",
    "    for speaker in speakers:\n",
    "        for chapter in speakers_chapters[speaker]:\n",
    "            for file in speakers_chapters[speaker][chapter]:\n",
    "                training_label.append(labels[speaker])\n",
    "\n",
    "\n",
    "    training_data = sum(training_data,[])\n",
    "    training_data = np.array(training_data)\n",
    "    training_label = np.array(training_label)\n",
    "    '''\n",
    "    I save the mfcc features and their corresponding labels into two seperate arraies which can be used for \n",
    "    training and testing later.\n",
    "    '''\n",
    "    pickle.dump(training_data, open(\"training_data\", \"wb\"))\n",
    "    pickle.dump(training_label, open(\"training_label\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets by pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = pickle.load(open(\"training_data\", \"rb\"))\n",
    "training_label = pickle.load(open(\"training_label\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import specific libraries for naive classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start playing with these classifiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the training data into training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_label, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.77 (+/- 0.21)\n",
      "Logisctic Accuracy: 0.77 (+/- 0.21)\n",
      "MLP Accuracy: 0.82 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier\n",
    "clf_svm = svm.SVC(kernel='linear', degree = 1, C=1).fit(X_train, y_train)\n",
    "scores = cross_val_score(clf_svm, training_data, training_label, cv=5)\n",
    "print(\"SVM Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#logistic regressiong classifier\n",
    "clf_log = LogisticRegression(C=1, penalty='l1', tol=0.1).fit(X_train, y_train)\n",
    "scores = cross_val_score(clf_log, training_data, training_label, cv=5)\n",
    "print(\"Logisctic Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#multilayer Perceptron\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(20, 10), random_state=1).fit(X_train, y_train)\n",
    "scores = cross_val_score(clf_mlp, training_data, training_label, cv=5)\n",
    "print(\"MLP Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import specific libraries for CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start playing with CNN!\n",
    "\n",
    "First of all, I define two functions used as normalization and standardization to datasets. This is important because the input of the CNN should be normalized or standardized for a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(list_):\n",
    "    maximum = max(list_)\n",
    "    minimum = min(list_)\n",
    "    return (maximum - list_)/(maximum - minimum)\n",
    "\n",
    "def standardize(list_):\n",
    "    mean = list_.mean()\n",
    "    standard = list_.std()\n",
    "    return (list_ - mean)/standard\n",
    "\n",
    "norm_training_data = np.zeros((training_data.shape[0],training_data.shape[1]))\n",
    "for i in range(0, len(training_data)):\n",
    "    norm_training_data[i] = normalize(training_data[i])\n",
    "    \n",
    "stand_training_data = np.zeros((training_data.shape[0],training_data.shape[1]))\n",
    "for i in range(0, len(training_data)):\n",
    "    stand_training_data[i] = standardize(training_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I change the shape of the training data and testing data, because I need to apply tensorflow later,\n",
    "which requires a shape of 4 dimensional tensors as input, abd shape of (n,2) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the training data into training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(norm_training_data, training_label, test_size=0.1, random_state=0)\n",
    "y_train = np.eye(len(y_train),2)[y_train]\n",
    "y_test = np.eye(len(y_test),2)[y_test]\n",
    "\n",
    "X_train_flatten = X_train.flatten()\n",
    "train_x = np.vstack(X_train_flatten).reshape(X_train.shape[0],1,13,1).astype(np.float32)\n",
    "train_y = np.vstack(y_train)\n",
    "\n",
    "X_test_flatten = X_test.flatten()\n",
    "test_x = np.vstack(X_test_flatten).reshape(X_test.shape[0],1,13,1).astype(np.float32)\n",
    "test_y = np.vstack(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define two functions used as normalization and standardization to datasets. This is important because the input of the CNN should be normalized or standardized for a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I set the basic parameters of CNN and define weight, bias, convolution and pooling operations for later use.\n",
    "\n",
    "It is easily to see that the height and the width of input are 1 and 13, the ouput should be 0 or 1, represent as female of male, and the number of channel I set to 1, because we don't have any other features except mfcc.\n",
    "\n",
    "As for the kernel size, which is the size of the convolutional layer, I set the first kernel to size 5 and the second kernel to size 3. Because for human voice, I think the low frequency won't affect the high frequency too much and I set the second kernel to size 3 because I want to concentrate more on signle features.\n",
    "\n",
    "As for the depth and number of hidden layers, I set them randomly according to others' experience. But I set the learning rate and training epochs slightly bigger because I believe increase these values will ensure the model converge faster. However, there is a potentional problem that the solution would oscilate around the optimal solution because the learning rate is too high. Anyway, in my case, I don't have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_height = 1\n",
    "input_width = 13\n",
    "num_labels = 2\n",
    "num_channels = 1\n",
    "\n",
    "batch_size = 20\n",
    "kernel_size = 5\n",
    "depth = 30\n",
    "num_hidden = 1000\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 50\n",
    "\n",
    "total_batchs = X_train.shape[0] // batch_size\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def apply_depthwise_conv(x,kernel_size,num_channels,depth):\n",
    "    weights = weight_variable([1, kernel_size, num_channels, depth])\n",
    "    biases = bias_variable([depth * num_channels])\n",
    "    return tf.nn.relu(tf.add(tf.nn.depthwise_conv2d(x,weights, [1, 1, 1, 1], padding='VALID'),biases))\n",
    "    \n",
    "def apply_max_pool(x,kernel_size,stride_size):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, kernel_size, 1], \n",
    "                          strides=[1, 1, stride_size, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define the layers of my CNN architecture, and I use softmax as my final layer at the end of CNN, because the ouput is only 0 and 1, so using softmax, representation of logistic regression in this case, is more reasonable. And I use gradient descent for loss optimization because the training set is not too big and gradient descent can help me achieve optimal solution accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,input_height,input_width,num_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,num_labels])\n",
    "\n",
    "c = apply_depthwise_conv(X,kernel_size,num_channels,depth)\n",
    "p = apply_max_pool(c,2,1)\n",
    "c = apply_depthwise_conv(p,3,depth*num_channels,depth//10)\n",
    "\n",
    "shape = c.get_shape().as_list()\n",
    "c_flat = tf.reshape(c, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "f_weights_l1 = weight_variable([shape[1] * shape[2] * depth * num_channels * (depth//10), num_hidden])\n",
    "f_biases_l1 = bias_variable([num_hidden])\n",
    "f = tf.nn.tanh(tf.add(tf.matmul(c_flat, f_weights_l1),f_biases_l1))\n",
    "\n",
    "out_weights = weight_variable([num_hidden, num_labels])\n",
    "out_biases = bias_variable([num_labels])\n",
    "\n",
    "y_ = tf.nn.softmax(tf.matmul(f, out_weights) + out_biases)\n",
    "loss = -tf.reduce_sum(Y * tf.log(y_))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "cost_history = np.empty(shape=[1],dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I begin to train my CNN, epoch represents the times I train and each time I train total_batches number of times. And at the end, I test the model by testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-a13a0c4555b5>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch:  0  Training Loss:  8.24281  Training Accuracy:  0.785773\n",
      "Epoch:  5  Training Loss:  6.63318  Training Accuracy:  0.842105\n",
      "Epoch:  10  Training Loss:  6.37844  Training Accuracy:  0.874589\n",
      "Epoch:  15  Training Loss:  6.64336  Training Accuracy:  0.85773\n",
      "Epoch:  20  Training Loss:  7.81959  Training Accuracy:  0.901727\n",
      "Epoch:  25  Training Loss:  6.9914  Training Accuracy:  0.898026\n",
      "Epoch:  30  Training Loss:  7.30063  Training Accuracy:  0.915707\n",
      "Epoch:  35  Training Loss:  7.89846  Training Accuracy:  0.889391\n",
      "Epoch:  40  Training Loss:  5.10765  Training Accuracy:  0.916118\n",
      "Epoch:  45  Training Loss:  6.46669  Training Accuracy:  0.92023\n",
      "Testing Accuracy: 0.926199\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for epoch in range(training_epochs):\n",
    "        for b in range(total_batchs):    \n",
    "            offset = (b * batch_size) % (train_y.shape[0] - batch_size)\n",
    "            batch_x = train_x[offset:(offset + batch_size), :, :, :]\n",
    "            batch_y = train_y[offset:(offset + batch_size), :]\n",
    "            _, c = session.run([optimizer, loss],feed_dict={X: batch_x, Y : batch_y})\n",
    "            cost_history = np.append(cost_history,c)\n",
    "        if epoch%5 == 0:\n",
    "            print (\"Epoch: \",epoch,\" Training Loss: \",c,\" Training Accuracy: \",\n",
    "              session.run(accuracy, feed_dict={X: train_x, Y: train_y}))\n",
    "    print (\"Testing Accuracy:\", session.run(accuracy, feed_dict={X: test_x, Y: test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusionly, I have tested four methods for audio classification. They are: linear SVM with degree 1, Logistic regression (classification), Multilayer perceptron and Convolutional neural network. Generally, the performances varies from model to model. I have 77% accuracy for SVM, 78% for logistic, 82% for MLP and around 93% for CNN.\n",
    "\n",
    "It is a bit weird to see that SVM worse than logistic, I think it is because I only use linear method, instead of poly, with only degree 1 for model training. I increase the degree of linear SVM model but the results don't improve too much. I try to use poly SVM but it costs lots of time so that I give up this method. But theoratically, SVM should work better than naive logistics in most cases. \n",
    "\n",
    "As for MLP, it performs better than previous two, because of it is kind of neural networks which perform better on classification overall. However, due to the existance of CNN, which can learn features in unstructured data, I don't think I need to consume more time on tuning the MLP parameters.\n",
    "\n",
    "CNN, as one of the most popular deep learning networks, has a state of art performance not only on image classification and recognition, but also on audio classfication and feature extraction. In my experiment, I try to use a CNN architecture as simple as possible, that I only use two convolutional layers and one pooing layers. I iterate only 50 times and have already received a much better result with 93% accuracy. But the main difficulties of CNN are choosing the number of layers, also known as model architecture, and tuning the parameters reasonably and efficiently. Sometimes, I encounter a common problem that the model converge to a local optimization and I have to retrain or change the model parameters. But anyway, CNN performances best in these four methods and it worth me writing and finding the optimal solution.\n",
    "\n",
    "In a word, CNN has the best accuracy without doubt, MLP works also fine, SVM and Logistic regression look similar in my case, but I believe SVM can performs better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
